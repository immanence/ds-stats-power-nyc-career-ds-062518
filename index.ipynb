{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Analysis\n",
    "\n",
    "### SWABT:\n",
    "\n",
    "* Describe the concept of \"Power\" in relation to p-value and effect size for hypothesis testing. \n",
    "* Understand and critically evaluate the factors influencing the power of an experiment.\n",
    "* Perform Power calculation using Scipy and Python.\n",
    "* Demonstrate the impact of sample size on statistical power using simulations.\n",
    "* Demonstrate the combined effect of sample size and effect size on statistical power using simulations.\n",
    "\n",
    "\n",
    "### Overview\n",
    "\n",
    "\n",
    "Power analysis is an important aspect of experimental design. It allows us to determine the sample size required to detect an effect of a given size with a given degree of confidence. Conversely, it allows us to determine the probability of detecting an effect of a given size with a given level of confidence, under sample size constraints. If the probability is unacceptably low, we would be wise to alter or abandon the experiment.\n",
    "\n",
    "The following four quantities have an intimate relationship:\n",
    "\n",
    "* Sample size\n",
    "* Effect size\n",
    "* Significance level = P (Type I error) = probability of finding an effect that is not there\n",
    "* **Power = 1 - P (Type II error)** = probability of finding an effect that is there\n",
    "\n",
    "Given any three, we can determine the fourth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we will consider a general-purpose simulation approach to estimating the power of an experimental design.\n",
    "\n",
    "Consider a scenario with an expected effect size and sample size and we would like to know the associated power. For our example experiment, we will use a design with two factors: \n",
    "\n",
    "1. 30 participants per group\n",
    "2. A ‘large’ effect size (Cohen’s d = 0.8). \n",
    "\n",
    "Here, we will determine the power of this test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# No. of groups\n",
    "groups = 2\n",
    "\n",
    "# No. of samples\n",
    "n = 30\n",
    "\n",
    "# No. of simulations\n",
    "sims = 10000\n",
    "\n",
    "# Effect size = 0.8, same standard deviation for both groups\n",
    "# Use two lists to store mean and sigma values\n",
    "means = [0.0, 0.8] \n",
    "sigmas = [1.0, 1.0]\n",
    "\n",
    "# Initialize a numpy array with size equal to sims and fill with nans. Store the p value for each simulation later\n",
    "p_val = np.empty(sims)\n",
    "p_val.fill(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Power\n",
    "\n",
    "We shall now perform a large number of simulated experiments, each time calculating our test statistic (independent samples t-test, in this case) and counting the number of times we reject the null hypothesis. The power is simply the proportion of times that we are able to reject the null hypothesis (remembering that we control the population means and we know that there is a true difference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Run a for loop for range of values in sims\n",
    "\n",
    "\n",
    "    # Create a numpy array \"data\" with size (no. of samples x no. of groups) and fill with Nans\n",
    "\n",
    "    # Simulate the data for experiment for 2 groups using a for loop \n",
    "\n",
    "\n",
    "        # Generate normal distribution for both groups described above and save in the data array under different index\n",
    "        data[:, group] = None\n",
    "    \n",
    "    # Run an independant t-test on generated distributions stored in numpy array \n",
    "    result = None\n",
    "    \n",
    "    # Store the p value with simulation number \n",
    "    p_val[sim] = None\n",
    "\n",
    "# number of simulations where the null was rejected\n",
    "rejects = None\n",
    "reject_proportion = None\n",
    "\n",
    "# Print the reject proportion as power\n",
    "\n",
    "# Power:  0.855"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our power to detect a large effect size with 30 participants per group in a between-subjects design is about 86%. That is, if a large effect size is truly present then we would expect to be able to reject the null hypothesis (at an alpha of 0.05) about 86% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate sample size to achieve a *given power* for a *given effect size*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a scenario where you have a design and effect size in mind and would like to know what sample size you would need to achieve a particular power e.g. 80%. This is a straightforward extension of the previous example: we begin with a sample size and calculate the associated power. We then perform such a calculation repeatedly, each time increasing the sample size, until the power has reached the desired level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation code shown above can be slightly modified to improve speed of execution (i.e. the computational cost, which must be considered at all times while running large tests). Let’s make some tweaks to allow the simulations to be performed quicker. \n",
    "\n",
    "In the code below, we generate the simulated data all at once and then use the axis argument to `scipy.stats.ttest_ind` to perform the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulation(power, cohen_d):\n",
    "    \n",
    "    # initialize with 20 samples per group \n",
    "    n = None\n",
    "    \n",
    "    # Identify the effect size between groups\n",
    "    means = None\n",
    "    sigmas = None\n",
    "\n",
    "    # No. of groups\n",
    "    groups = None\n",
    "\n",
    "    # Set 10000 simulations\n",
    "    sims = None\n",
    "\n",
    "    # power level that we would like to reach\n",
    "    power_target = None\n",
    "\n",
    "    # initialise the power for the current sample size to a small value\n",
    "    power_current = 0.0\n",
    "    pow_samp = []\n",
    "    \n",
    "    # keep iterating until desired power is obtained\n",
    "    while power_current < power_target:\n",
    "        \n",
    "        # create a numpy array with dimensions [sims, n, groups] and fill with nans\n",
    "\n",
    "        # generate ransom samples for both groups and run t tests\n",
    "        for group in range(groups):\n",
    "\n",
    "            data[:, :, group] =  None\n",
    "\n",
    "        result = None\n",
    "\n",
    "        p_val = None\n",
    "\n",
    "        # Number of simulations where the null hypothesis was rejected\n",
    "        rejects = None\n",
    "        \n",
    "        # Calculate reject proportion\n",
    "        reject_proportion = None\n",
    "\n",
    "        power_current =  reject_proportion\n",
    "\n",
    "        # print (\"With\", n,\"samples per group, Power =\", power_current)\n",
    "        # append results to pow_samp\n",
    "\n",
    "        # increase the number of samples by one for the next iteration of the loop\n",
    "      \n",
    "    return pow_samp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set the value for required power and effect size to calculate the number of samples required to achieve the specified level of power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Power and Cohen'd - Change these values and observe the effect on the outcome. \n",
    "set_power = 1\n",
    "set_d = 0.8\n",
    "\n",
    "#  Plot power vs sample size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure shows a decelerating relationship between the number of samples in each group and the power. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**EXERCISE: Calculating power across varying sample and effect sizes**\n",
    "\n",
    ">In the previous examples, we have assumed a fixed (‘large’) effect size. However, perhaps we want to investigate how power changes with both effect size and sample size. This is again a straightforward extension of the previous example. \n",
    "\n",
    ">1. Generate samples with sizes ranging from 10 to 50 per group\n",
    "2. Set effect size from less than small (i.e. 0.2) to slightly bigger than large (0.8)\n",
    "3. set number of simulations to 10000\n",
    "4. Use nested For loop i.e. for all chosen effect sizes,for all chosen sample sizes, for all groups (i.e. 2) - run the 2 sample independant test and store power, chosen sample size and effect size\n",
    "5. Visualize your data in a meaningful way to communicate results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that the power for a given combination of effect size and sample size per group is represented by the luminance of the relevant cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "\n",
    "In this lesson, we recieved an understanding around the idea of \"statistical power\" and how sample size, p_value and effect size impact the power of an experiment. We ran a simulation to determine the sample size that would provide a given value of power. In the second simulation, we saw the combined effect of sample size and effect size on the power. We can conclude this lesson with the ideas that a) Statistical power increases as we increase the sample size and b) with a small effect size, we require a large number of samples to achieve required power and vice versa. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
